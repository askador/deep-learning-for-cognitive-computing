{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.python.keras.optimizers import adam_v2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import argmax\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500) \n",
    "pd.set_option('display.max_rows', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./penguins.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>33.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Dream</td>\n",
       "      <td>40.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>184.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>45.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>198.0</td>\n",
       "      <td>3950.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Dream</td>\n",
       "      <td>42.2</td>\n",
       "      <td>18.5</td>\n",
       "      <td>180.0</td>\n",
       "      <td>3550.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Dream</td>\n",
       "      <td>36.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>187.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>45.5</td>\n",
       "      <td>13.9</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>53.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>49.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>216.0</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>41.3</td>\n",
       "      <td>21.1</td>\n",
       "      <td>195.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.7</td>\n",
       "      <td>18.4</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "70      Adelie  Torgersen            33.5           19.0              190.0   \n",
       "33      Adelie      Dream            40.9           18.9              184.0   \n",
       "281  Chinstrap      Dream            45.2           17.8              198.0   \n",
       "37      Adelie      Dream            42.2           18.5              180.0   \n",
       "94      Adelie      Dream            36.2           17.3              187.0   \n",
       "198     Gentoo     Biscoe            45.5           13.9              210.0   \n",
       "259     Gentoo     Biscoe            53.4           15.8              219.0   \n",
       "248     Gentoo     Biscoe            49.4           15.8              216.0   \n",
       "61      Adelie     Biscoe            41.3           21.1              195.0   \n",
       "71      Adelie  Torgersen            39.7           18.4              190.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "70        3600.0  female  \n",
       "33        3900.0    male  \n",
       "281       3950.0  female  \n",
       "37        3550.0  female  \n",
       "94        3300.0  female  \n",
       "198       4200.0  female  \n",
       "259       5500.0    male  \n",
       "248       4925.0    male  \n",
       "61        4400.0    male  \n",
       "71        3900.0    male  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adelie', 'Chinstrap', 'Gentoo'], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('species', axis=1)\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'], dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_arguments = X.select_dtypes(exclude=['object']).columns\n",
    "num_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['island', 'sex'], dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_arguments = X.select_dtypes(include=['object']).columns\n",
    "cat_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler()\n",
    "scaler_X.fit(X[num_arguments])\n",
    "X[num_arguments] = scaler_X.transform(X[num_arguments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arg in cat_arguments:\n",
    "    one_hot = pd.get_dummies(X[arg], prefix=arg)\n",
    "    X = X.drop(arg, axis = 1)\n",
    "    X = X.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70        Adelie\n",
       "33        Adelie\n",
       "281    Chinstrap\n",
       "37        Adelie\n",
       "94        Adelie\n",
       "198       Gentoo\n",
       "259       Gentoo\n",
       "248       Gentoo\n",
       "61        Adelie\n",
       "71        Adelie\n",
       "87        Adelie\n",
       "78        Adelie\n",
       "86        Adelie\n",
       "241       Gentoo\n",
       "93        Adelie\n",
       "73        Adelie\n",
       "305    Chinstrap\n",
       "336    Chinstrap\n",
       "229       Gentoo\n",
       "74        Adelie\n",
       "239       Gentoo\n",
       "4         Adelie\n",
       "221       Gentoo\n",
       "145       Adelie\n",
       "52        Adelie\n",
       "314    Chinstrap\n",
       "194       Gentoo\n",
       "228       Gentoo\n",
       "247       Gentoo\n",
       "343    Chinstrap\n",
       "27        Adelie\n",
       "187       Gentoo\n",
       "151       Adelie\n",
       "323    Chinstrap\n",
       "262       Gentoo\n",
       "35        Adelie\n",
       "20        Adelie\n",
       "138       Adelie\n",
       "320    Chinstrap\n",
       "53        Adelie\n",
       "311    Chinstrap\n",
       "148       Adelie\n",
       "84        Adelie\n",
       "269       Gentoo\n",
       "249       Gentoo\n",
       "192       Gentoo\n",
       "324    Chinstrap\n",
       "317    Chinstrap\n",
       "217       Gentoo\n",
       "339    Chinstrap\n",
       "88        Adelie\n",
       "288    Chinstrap\n",
       "235       Gentoo\n",
       "155       Gentoo\n",
       "100       Adelie\n",
       "297    Chinstrap\n",
       "263       Gentoo\n",
       "50        Adelie\n",
       "225       Gentoo\n",
       "98        Adelie\n",
       "56        Adelie\n",
       "285    Chinstrap\n",
       "158       Gentoo\n",
       "19        Adelie\n",
       "22        Adelie\n",
       "289    Chinstrap\n",
       "277    Chinstrap\n",
       "181       Gentoo\n",
       "223       Gentoo\n",
       "238       Gentoo\n",
       "332    Chinstrap\n",
       "190       Gentoo\n",
       "254       Gentoo\n",
       "102       Adelie\n",
       "252       Gentoo\n",
       "131       Adelie\n",
       "335    Chinstrap\n",
       "5         Adelie\n",
       "0         Adelie\n",
       "189       Gentoo\n",
       "175       Gentoo\n",
       "92        Adelie\n",
       "200       Gentoo\n",
       "318    Chinstrap\n",
       "143       Adelie\n",
       "206       Gentoo\n",
       "265       Gentoo\n",
       "313    Chinstrap\n",
       "177       Gentoo\n",
       "2         Adelie\n",
       "203       Gentoo\n",
       "222       Gentoo\n",
       "182       Gentoo\n",
       "161       Gentoo\n",
       "331    Chinstrap\n",
       "68        Adelie\n",
       "240       Gentoo\n",
       "191       Gentoo\n",
       "66        Adelie\n",
       "150       Adelie\n",
       "284    Chinstrap\n",
       "25        Adelie\n",
       "81        Adelie\n",
       "188       Gentoo\n",
       "67        Adelie\n",
       "219       Gentoo\n",
       "168       Gentoo\n",
       "226       Gentoo\n",
       "183       Gentoo\n",
       "38        Adelie\n",
       "40        Adelie\n",
       "58        Adelie\n",
       "30        Adelie\n",
       "325    Chinstrap\n",
       "237       Gentoo\n",
       "141       Adelie\n",
       "42        Adelie\n",
       "96        Adelie\n",
       "328    Chinstrap\n",
       "127       Adelie\n",
       "103       Adelie\n",
       "214       Gentoo\n",
       "338    Chinstrap\n",
       "128       Adelie\n",
       "114       Adelie\n",
       "119       Adelie\n",
       "97        Adelie\n",
       "83        Adelie\n",
       "17        Adelie\n",
       "233       Gentoo\n",
       "330    Chinstrap\n",
       "31        Adelie\n",
       "296    Chinstrap\n",
       "89        Adelie\n",
       "13        Adelie\n",
       "29        Adelie\n",
       "124       Adelie\n",
       "283    Chinstrap\n",
       "173       Gentoo\n",
       "144       Adelie\n",
       "99        Adelie\n",
       "21        Adelie\n",
       "135       Adelie\n",
       "312    Chinstrap\n",
       "342    Chinstrap\n",
       "276    Chinstrap\n",
       "75        Adelie\n",
       "231       Gentoo\n",
       "227       Gentoo\n",
       "204       Gentoo\n",
       "112       Adelie\n",
       "157       Gentoo\n",
       "18        Adelie\n",
       "279    Chinstrap\n",
       "126       Adelie\n",
       "134       Adelie\n",
       "329    Chinstrap\n",
       "147       Adelie\n",
       "162       Gentoo\n",
       "322    Chinstrap\n",
       "319    Chinstrap\n",
       "45        Adelie\n",
       "230       Gentoo\n",
       "122       Adelie\n",
       "196       Gentoo\n",
       "224       Gentoo\n",
       "172       Gentoo\n",
       "290    Chinstrap\n",
       "113       Adelie\n",
       "165       Gentoo\n",
       "32        Adelie\n",
       "1         Adelie\n",
       "23        Adelie\n",
       "166       Gentoo\n",
       "184       Gentoo\n",
       "152       Gentoo\n",
       "291    Chinstrap\n",
       "286    Chinstrap\n",
       "140       Adelie\n",
       "340    Chinstrap\n",
       "44        Adelie\n",
       "79        Adelie\n",
       "160       Gentoo\n",
       "132       Adelie\n",
       "232       Gentoo\n",
       "199       Gentoo\n",
       "43        Adelie\n",
       "163       Gentoo\n",
       "264       Gentoo\n",
       "174       Gentoo\n",
       "213       Gentoo\n",
       "129       Adelie\n",
       "15        Adelie\n",
       "95        Adelie\n",
       "295    Chinstrap\n",
       "245       Gentoo\n",
       "24        Adelie\n",
       "274       Gentoo\n",
       "101       Adelie\n",
       "255       Gentoo\n",
       "146       Adelie\n",
       "310    Chinstrap\n",
       "14        Adelie\n",
       "80        Adelie\n",
       "76        Adelie\n",
       "110       Adelie\n",
       "337    Chinstrap\n",
       "321    Chinstrap\n",
       "306    Chinstrap\n",
       "91        Adelie\n",
       "267       Gentoo\n",
       "270       Gentoo\n",
       "253       Gentoo\n",
       "136       Adelie\n",
       "149       Adelie\n",
       "266       Gentoo\n",
       "115       Adelie\n",
       "301    Chinstrap\n",
       "34        Adelie\n",
       "210       Gentoo\n",
       "90        Adelie\n",
       "64        Adelie\n",
       "246       Gentoo\n",
       "197       Gentoo\n",
       "261       Gentoo\n",
       "170       Gentoo\n",
       "208       Gentoo\n",
       "46        Adelie\n",
       "59        Adelie\n",
       "82        Adelie\n",
       "216       Gentoo\n",
       "62        Adelie\n",
       "300    Chinstrap\n",
       "307    Chinstrap\n",
       "167       Gentoo\n",
       "117       Adelie\n",
       "48        Adelie\n",
       "121       Adelie\n",
       "272       Gentoo\n",
       "49        Adelie\n",
       "298    Chinstrap\n",
       "65        Adelie\n",
       "244       Gentoo\n",
       "179       Gentoo\n",
       "180       Gentoo\n",
       "63        Adelie\n",
       "202       Gentoo\n",
       "16        Adelie\n",
       "294    Chinstrap\n",
       "105       Adelie\n",
       "85        Adelie\n",
       "77        Adelie\n",
       "287    Chinstrap\n",
       "315    Chinstrap\n",
       "106       Adelie\n",
       "258       Gentoo\n",
       "120       Adelie\n",
       "60        Adelie\n",
       "308    Chinstrap\n",
       "41        Adelie\n",
       "55        Adelie\n",
       "72        Adelie\n",
       "36        Adelie\n",
       "6         Adelie\n",
       "118       Adelie\n",
       "111       Adelie\n",
       "108       Adelie\n",
       "207       Gentoo\n",
       "125       Adelie\n",
       "341    Chinstrap\n",
       "220       Gentoo\n",
       "69        Adelie\n",
       "28        Adelie\n",
       "242       Gentoo\n",
       "251       Gentoo\n",
       "304    Chinstrap\n",
       "54        Adelie\n",
       "205       Gentoo\n",
       "278    Chinstrap\n",
       "164       Gentoo\n",
       "109       Adelie\n",
       "193       Gentoo\n",
       "195       Gentoo\n",
       "171       Gentoo\n",
       "116       Adelie\n",
       "123       Adelie\n",
       "159       Gentoo\n",
       "316    Chinstrap\n",
       "186       Gentoo\n",
       "107       Adelie\n",
       "215       Gentoo\n",
       "137       Adelie\n",
       "133       Adelie\n",
       "260       Gentoo\n",
       "26        Adelie\n",
       "7         Adelie\n",
       "185       Gentoo\n",
       "326    Chinstrap\n",
       "139       Adelie\n",
       "12        Adelie\n",
       "302    Chinstrap\n",
       "257       Gentoo\n",
       "130       Adelie\n",
       "309    Chinstrap\n",
       "327    Chinstrap\n",
       "212       Gentoo\n",
       "201       Gentoo\n",
       "57        Adelie\n",
       "333    Chinstrap\n",
       "104       Adelie\n",
       "273       Gentoo\n",
       "334    Chinstrap\n",
       "292    Chinstrap\n",
       "142       Adelie\n",
       "156       Gentoo\n",
       "250       Gentoo\n",
       "39        Adelie\n",
       "176       Gentoo\n",
       "303    Chinstrap\n",
       "211       Gentoo\n",
       "209       Gentoo\n",
       "280    Chinstrap\n",
       "236       Gentoo\n",
       "169       Gentoo\n",
       "234       Gentoo\n",
       "51        Adelie\n",
       "293    Chinstrap\n",
       "243       Gentoo\n",
       "275       Gentoo\n",
       "153       Gentoo\n",
       "282    Chinstrap\n",
       "299    Chinstrap\n",
       "154       Gentoo\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>island_Biscoe</th>\n",
       "      <th>island_Dream</th>\n",
       "      <th>island_Torgersen</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.621818</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.650909</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.178182</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "169        0.621818       0.250000           0.830508     1.000000   \n",
       "277        0.650909       0.761905           0.406780     0.333333   \n",
       "44         0.178182       0.452381           0.220339     0.083333   \n",
       "\n",
       "     island_Biscoe  island_Dream  island_Torgersen  sex_female  sex_male  \n",
       "169              1             0                 0           0         1  \n",
       "277              0             1                 0           0         1  \n",
       "44               0             1                 0           1         0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[[169, 277, 44]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_y = LabelEncoder()\n",
    "y = encoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    2: 'Gentoo',\n",
    "    1: 'Chinstrap',\n",
    "    0: 'Adelie',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233, 9)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_layer(neurons, learning_rate):\n",
    "    model = Sequential([\n",
    "        Dense(neurons, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=adam_v2.Adam(learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_layer(neurons, hidden_layers, learning_rate, dropout=.5):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "\n",
    "    for i in range(hidden_layers):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=adam_v2.Adam(learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_list = [2, 36]\n",
    "hidden_layers_list = [0, 3]\n",
    "dropouts = [0.2, 0.4]\n",
    "epochs_list = [3, 100]\n",
    "learning_rates = [0.1, 0.01]\n",
    "batch_sizes = [8, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_layer_results_table = pd.DataFrame(columns=['accuracy', 'loss', 'learning_rate', 'neurons', 'epochs', 'batch_size'])\n",
    "multi_layer_results_table = pd.DataFrame(columns=['accuracy', 'loss', 'learning_rate', 'neurons', 'hidden_layers', 'dropout', 'epochs', 'batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_parameters = [\n",
    "    neurons_list,\n",
    "    epochs_list,\n",
    "    learning_rates,\n",
    "    batch_sizes\n",
    "]\n",
    "\n",
    "ml_parameters = [\n",
    "    neurons_list,\n",
    "    hidden_layers_list,\n",
    "    dropouts,\n",
    "    epochs_list,\n",
    "    learning_rates,\n",
    "    batch_sizes\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2892846922.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "for neurons, epochs, learning_rate, batch_size in list(itertools.product(*sl_parameters)):\n",
    "    sl_model = single_layer(neurons, learning_rate)\n",
    "    \n",
    "    history = sl_model.fit(X_train, y_train, epochs=epochs, validation_split=0.2, batch_size=batch_size, verbose=0)\n",
    "    loss, accuracy = sl_model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    d_row = {\n",
    "        'accuracy': accuracy, \n",
    "        'loss': loss, \n",
    "        'learning_rate': learning_rate,\n",
    "        'neurons': neurons,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size\n",
    "    }\n",
    "    \n",
    "    single_layer_results_table = single_layer_results_table.append(d_row,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_29796\\2594169634.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "for neurons, hidden_layers, dropout, epochs, learning_rate, batch_size in list(itertools.product(*ml_parameters)):\n",
    "    ml_model = multi_layer(neurons, hidden_layers, learning_rate, dropout)\n",
    "    \n",
    "    history = ml_model.fit(X_train, y_train, epochs=epochs, validation_split=0.2, batch_size=batch_size, verbose=0)\n",
    "    loss, accuracy = ml_model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    d_row = {\n",
    "        'accuracy': accuracy, \n",
    "        'loss': loss, \n",
    "        'learning_rate': learning_rate,\n",
    "        'neurons': neurons,\n",
    "        'hidden_layers': hidden_layers, \n",
    "        'dropout': dropout,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size\n",
    "    }\n",
    "    \n",
    "    multi_layer_results_table = multi_layer_results_table.append(d_row,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>neurons</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.44</td>\n",
       "      <td>1.074527</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.746930</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.526681</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.283831</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.330707</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.097646</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.182312</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.038478</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.045127</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy      loss  learning_rate  neurons  epochs  batch_size\n",
       "3       0.44  1.074527           0.01      2.0     3.0        32.0\n",
       "2       0.73  0.746930           0.01      2.0     3.0         8.0\n",
       "1       0.79  0.526681           0.10      2.0     3.0        32.0\n",
       "0       0.80  0.283831           0.10      2.0     3.0         8.0\n",
       "11      0.94  0.330707           0.01     36.0     3.0        32.0\n",
       "4       0.96  0.097646           0.10      2.0   100.0         8.0\n",
       "10      0.98  0.182312           0.01     36.0     3.0         8.0\n",
       "8       0.99  0.038478           0.10     36.0     3.0         8.0\n",
       "9       0.99  0.045127           0.10     36.0     3.0        32.0\n",
       "5       1.00  0.002894           0.10      2.0   100.0        32.0\n",
       "6       1.00  0.006483           0.01      2.0   100.0         8.0\n",
       "7       1.00  0.025500           0.01      2.0   100.0        32.0\n",
       "12      1.00  0.000276           0.10     36.0   100.0         8.0\n",
       "13      1.00  0.000469           0.10     36.0   100.0        32.0\n",
       "14      1.00  0.001355           0.01     36.0   100.0         8.0\n",
       "15      1.00  0.003562           0.01     36.0   100.0        32.0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_layer_results_table.sort_values(by='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>neurons</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.36</td>\n",
       "      <td>1.056831</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.834254</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.44</td>\n",
       "      <td>1.052026</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.44</td>\n",
       "      <td>1.052296</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.44</td>\n",
       "      <td>1.069912</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.908661</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.44</td>\n",
       "      <td>1.052186</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.44</td>\n",
       "      <td>1.051574</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.44</td>\n",
       "      <td>1.053391</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.44</td>\n",
       "      <td>1.050960</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.44</td>\n",
       "      <td>1.053506</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.864518</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.44</td>\n",
       "      <td>1.052907</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.868716</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.44</td>\n",
       "      <td>1.055197</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.44</td>\n",
       "      <td>1.054918</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.44</td>\n",
       "      <td>1.051713</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.877928</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.910296</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.924899</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.457467</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.687171</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.603827</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.404029</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.425372</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.527348</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.644446</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.517302</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.390465</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.610804</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.221321</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.249693</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.310697</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.539373</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.331170</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.119960</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.168425</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.061469</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.273645</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.042826</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.032546</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.134355</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.088769</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.031740</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.029725</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.007608</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.030410</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.009172</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.007539</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy      loss  learning_rate  neurons  hidden_layers  dropout  \\\n",
       "17      0.36  1.056831           0.10      2.0            3.0      0.2   \n",
       "31      0.44  0.834254           0.01      2.0            3.0      0.4   \n",
       "29      0.44  1.052026           0.10      2.0            3.0      0.4   \n",
       "28      0.44  1.052296           0.10      2.0            3.0      0.4   \n",
       "27      0.44  1.069912           0.01      2.0            3.0      0.4   \n",
       "26      0.44  0.908661           0.01      2.0            3.0      0.4   \n",
       "25      0.44  1.052186           0.10      2.0            3.0      0.4   \n",
       "24      0.44  1.051574           0.10      2.0            3.0      0.4   \n",
       "21      0.44  1.053391           0.10      2.0            3.0      0.2   \n",
       "20      0.44  1.050960           0.10      2.0            3.0      0.2   \n",
       "18      0.44  1.053506           0.01      2.0            3.0      0.2   \n",
       "16      0.44  0.864518           0.10      2.0            3.0      0.2   \n",
       "52      0.44  1.052907           0.10     36.0            3.0      0.2   \n",
       "19      0.44  0.868716           0.01      2.0            3.0      0.2   \n",
       "56      0.44  1.055197           0.10     36.0            3.0      0.4   \n",
       "60      0.44  1.054918           0.10     36.0            3.0      0.4   \n",
       "61      0.44  1.051713           0.10     36.0            3.0      0.4   \n",
       "53      0.54  0.877928           0.10     36.0            3.0      0.2   \n",
       "35      0.63  0.910296           0.01     36.0            0.0      0.2   \n",
       "3       0.70  0.924899           0.01      2.0            0.0      0.2   \n",
       "49      0.70  0.457467           0.10     36.0            3.0      0.2   \n",
       "48      0.71  0.687171           0.10     36.0            3.0      0.2   \n",
       "59      0.74  0.603827           0.01     36.0            3.0      0.4   \n",
       "57      0.80  0.404029           0.10     36.0            3.0      0.4   \n",
       "22      0.80  0.425372           0.01      2.0            3.0      0.2   \n",
       "23      0.80  0.527348           0.01      2.0            3.0      0.2   \n",
       "30      0.80  0.644446           0.01      2.0            3.0      0.4   \n",
       "2       0.81  0.517302           0.01      2.0            0.0      0.2   \n",
       "58      0.83  0.390465           0.01     36.0            3.0      0.4   \n",
       "11      0.83  0.610804           0.01      2.0            0.0      0.4   \n",
       "41      0.84  0.221321           0.10     36.0            0.0      0.4   \n",
       "51      0.87  0.249693           0.01     36.0            3.0      0.2   \n",
       "34      0.88  0.310697           0.01     36.0            0.0      0.2   \n",
       "43      0.89  0.539373           0.01     36.0            0.0      0.4   \n",
       "42      0.91  0.331170           0.01     36.0            0.0      0.4   \n",
       "1       0.93  0.119960           0.10      2.0            0.0      0.2   \n",
       "50      0.97  0.168425           0.01     36.0            3.0      0.2   \n",
       "8       0.98  0.061469           0.10      2.0            0.0      0.4   \n",
       "10      0.98  0.273645           0.01      2.0            0.0      0.4   \n",
       "0       0.99  0.042826           0.10      2.0            0.0      0.2   \n",
       "63      0.99  0.032546           0.01     36.0            3.0      0.4   \n",
       "9       0.99  0.134355           0.10      2.0            0.0      0.4   \n",
       "33      0.99  0.088769           0.10     36.0            0.0      0.2   \n",
       "32      0.99  0.031740           0.10     36.0            0.0      0.2   \n",
       "62      0.99  0.029725           0.01     36.0            3.0      0.4   \n",
       "4       1.00  0.000204           0.10      2.0            0.0      0.2   \n",
       "5       1.00  0.001737           0.10      2.0            0.0      0.2   \n",
       "6       1.00  0.004903           0.01      2.0            0.0      0.2   \n",
       "7       1.00  0.007608           0.01      2.0            0.0      0.2   \n",
       "12      1.00  0.001233           0.10      2.0            0.0      0.4   \n",
       "55      1.00  0.000015           0.01     36.0            3.0      0.2   \n",
       "54      1.00  0.000003           0.01     36.0            3.0      0.2   \n",
       "13      1.00  0.001293           0.10      2.0            0.0      0.4   \n",
       "40      1.00  0.030410           0.10     36.0            0.0      0.4   \n",
       "39      1.00  0.009172           0.01     36.0            0.0      0.2   \n",
       "47      1.00  0.007539           0.01     36.0            0.0      0.4   \n",
       "46      1.00  0.002891           0.01     36.0            0.0      0.4   \n",
       "45      1.00  0.002753           0.10     36.0            0.0      0.4   \n",
       "44      1.00  0.000292           0.10     36.0            0.0      0.4   \n",
       "36      1.00  0.000429           0.10     36.0            0.0      0.2   \n",
       "37      1.00  0.001154           0.10     36.0            0.0      0.2   \n",
       "38      1.00  0.003220           0.01     36.0            0.0      0.2   \n",
       "14      1.00  0.005915           0.01      2.0            0.0      0.4   \n",
       "15      1.00  0.006350           0.01      2.0            0.0      0.4   \n",
       "\n",
       "    epochs  batch_size  \n",
       "17     3.0        32.0  \n",
       "31   100.0        32.0  \n",
       "29   100.0        32.0  \n",
       "28   100.0         8.0  \n",
       "27     3.0        32.0  \n",
       "26     3.0         8.0  \n",
       "25     3.0        32.0  \n",
       "24     3.0         8.0  \n",
       "21   100.0        32.0  \n",
       "20   100.0         8.0  \n",
       "18     3.0         8.0  \n",
       "16     3.0         8.0  \n",
       "52   100.0         8.0  \n",
       "19     3.0        32.0  \n",
       "56     3.0         8.0  \n",
       "60   100.0         8.0  \n",
       "61   100.0        32.0  \n",
       "53   100.0        32.0  \n",
       "35     3.0        32.0  \n",
       "3      3.0        32.0  \n",
       "49     3.0        32.0  \n",
       "48     3.0         8.0  \n",
       "59     3.0        32.0  \n",
       "57     3.0        32.0  \n",
       "22   100.0         8.0  \n",
       "23   100.0        32.0  \n",
       "30   100.0         8.0  \n",
       "2      3.0         8.0  \n",
       "58     3.0         8.0  \n",
       "11     3.0        32.0  \n",
       "41     3.0        32.0  \n",
       "51     3.0        32.0  \n",
       "34     3.0         8.0  \n",
       "43     3.0        32.0  \n",
       "42     3.0         8.0  \n",
       "1      3.0        32.0  \n",
       "50     3.0         8.0  \n",
       "8      3.0         8.0  \n",
       "10     3.0         8.0  \n",
       "0      3.0         8.0  \n",
       "63   100.0        32.0  \n",
       "9      3.0        32.0  \n",
       "33     3.0        32.0  \n",
       "32     3.0         8.0  \n",
       "62   100.0         8.0  \n",
       "4    100.0         8.0  \n",
       "5    100.0        32.0  \n",
       "6    100.0         8.0  \n",
       "7    100.0        32.0  \n",
       "12   100.0         8.0  \n",
       "55   100.0        32.0  \n",
       "54   100.0         8.0  \n",
       "13   100.0        32.0  \n",
       "40     3.0         8.0  \n",
       "39   100.0        32.0  \n",
       "47   100.0        32.0  \n",
       "46   100.0         8.0  \n",
       "45   100.0        32.0  \n",
       "44   100.0         8.0  \n",
       "36   100.0         8.0  \n",
       "37   100.0        32.0  \n",
       "38   100.0         8.0  \n",
       "14   100.0         8.0  \n",
       "15   100.0        32.0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_layer_results_table.sort_values(by='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_samples = np.array([\n",
    "    [49.2, 15.2, 221.0, 6300.0],\n",
    "    [50.0, 19.5, 196.0, 3900.0],\n",
    "    [37.0, 16.9, 185.0, 3000.0],\n",
    "], dtype=np.float32)\n",
    "scaled_samples = scaler_X.transform(scaled_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_samples = np.array([\n",
    "    [1, 0, 0, 0, 1],\n",
    "    [0, 1, 0, 0, 1],\n",
    "    [0, 1, 0, 1, 0],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62181824, 0.25      , 0.83050859, 1.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.65090913, 0.76190472, 0.40677965, 0.33333337, 0.        ,\n",
       "        1.        , 0.        , 0.        , 1.        ],\n",
       "       [0.17818184, 0.4523809 , 0.22033894, 0.08333331, 0.        ,\n",
       "        1.        , 0.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = np.concatenate((scaled_samples, categorical_samples), axis=1)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SL Class prediction 1 : Gentoo\n",
      "ML Class prediction 1 : Gentoo\n",
      "SL Class prediction 2 : Chinstrap\n",
      "ML Class prediction 2 : Chinstrap\n",
      "SL Class prediction 3 : Adelie\n",
      "ML Class prediction 3 : Adelie\n"
     ]
    }
   ],
   "source": [
    "ml_yhat = ml_model.predict(samples)\n",
    "sl_yhat = sl_model.predict(samples)\n",
    "\n",
    "for i in range(len(ml_yhat)):\n",
    "    print('SL Class prediction {} : {}'.format(i+1, label_dict[int(argmax(sl_yhat[i]))]))\n",
    "    print('ML Class prediction {} : {}'.format(i+1, label_dict[int(argmax(ml_yhat[i]))]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e0a661408dd2e5d6e82762c2a3896b10b58a303515c0bde349ae540da99193a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
