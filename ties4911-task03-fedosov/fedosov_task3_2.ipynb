{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3-2\n",
    "\n",
    "Try various implementations of CNNs that are present in lecture materials using MNIST or Fashion MNIST (or any other you wish) dataset. You may try other examples you find in the web as well. Play with training hyper-parameters and network architecture, with dropouts, batch normalization and data generation. Build the table where compare performance (loss, accuracy) of the combinations you made.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
    "from tensorflow.python.keras import utils\n",
    "from tensorflow.python.keras.optimizers import adam_v2\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32) / 255.0\n",
    "X_test = X_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "    x_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=['name', 'accuracy', 'loss', 'layers', 'dense_layers', 'learning_rate', 'batch_size', 'epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(train_params):\n",
    "    model = Sequential()\n",
    "    \n",
    "    for i, layer in enumerate(train_params['layers']):\n",
    "        if i == 0:\n",
    "            model.add(Conv2D(layer['filters'], layer['kernel_size'], activation=layer['activation'], input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(Conv2D(layer['filters'], layer['kernel_size'], activation=layer['activation']))\n",
    "        if layer['batch_norm']:\n",
    "            model.add(BatchNormalization())\n",
    "        if layer['pool_size']:\n",
    "            model.add(MaxPooling2D(pool_size=layer['pool_size']))\n",
    "        if layer['dropout']:\n",
    "            model.add(Dropout(layer['dropout']))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for i, dense_layer in enumerate(train_params['dense_layers']):\n",
    "        model.add(Dense(dense_layer['units'], activation=dense_layer['activation']))\n",
    "        if dense_layer['batch_norm']:\n",
    "            model.add(BatchNormalization())\n",
    "        if dense_layer['dropout']:\n",
    "            model.add(Dropout(dense_layer['dropout']))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    optimizer = adam_v2.Adam(learning_rate=train_params['learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = [\n",
    "    {\n",
    "        'name': 'simplest',\n",
    "        'layers': [\n",
    "            {'filters': 64, 'kernel_size': (3, 3), 'activation': 'relu', 'batch_norm': False, 'pool_size': (2, 2), 'dropout': 0.25},\n",
    "        ],\n",
    "        'dense_layers': [\n",
    "            {'units': 128, 'activation': 'relu', 'batch_norm': True, 'dropout': 0.5},\n",
    "        ],\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64,\n",
    "        'epochs': 5\n",
    "    },\n",
    "    {\n",
    "        'name': 'deep',\n",
    "        'layers': [\n",
    "            {'filters': 32, 'kernel_size': (3, 3), 'activation': 'relu', 'batch_norm': True, 'pool_size': (2, 2), 'dropout': 0.2},\n",
    "            {'filters': 64, 'kernel_size': (3, 3), 'activation': 'relu', 'batch_norm': True, 'pool_size': (2, 2), 'dropout': 0.2},\n",
    "            {'filters': 128, 'kernel_size': (3, 3), 'activation': 'relu', 'batch_norm': True, 'pool_size': None, 'dropout': 0.3}\n",
    "        ],\n",
    "        'dense_layers': [\n",
    "            {'units': 64, 'activation': 'relu', 'batch_norm': True, 'dropout': 0.2},\n",
    "            {'units': 32, 'activation': 'relu', 'batch_norm': True, 'dropout': 0.2}\n",
    "        ],\n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 64,\n",
    "        'epochs': 5\n",
    "    },\n",
    "    {\n",
    "        'name': 'deepest',\n",
    "        'layers': [\n",
    "            {'filters': 32, 'kernel_size': (3, 3), 'activation': 'relu', 'batch_norm': True, 'pool_size': (2, 2), 'dropout': 0.2},\n",
    "            {'filters': 64, 'kernel_size': (3, 3), 'activation': 'relu', 'batch_norm': True, 'pool_size': (2, 2), 'dropout': 0.2},\n",
    "            {'filters': 128, 'kernel_size': (3, 3), 'activation': 'relu', 'batch_norm': True, 'pool_size': None, 'dropout': 0.5},\n",
    "            {'filters': 256, 'kernel_size': (3, 3), 'activation': 'relu', 'batch_norm': True, 'pool_size': None, 'dropout': 0.4}\n",
    "        ],\n",
    "        'dense_layers': [\n",
    "            {'units': 128, 'activation': 'relu', 'batch_norm': True, 'dropout': 0.2},\n",
    "            {'units': 64, 'activation': 'relu', 'batch_norm': True, 'dropout': 0.2},\n",
    "            {'units': 32, 'activation': 'relu', 'batch_norm': True, 'dropout': 0.2}\n",
    "        ],\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 64,\n",
    "        'epochs': 5\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 42s 44ms/step - loss: 0.4777 - accuracy: 0.8324 - val_loss: 0.3895 - val_accuracy: 0.8622\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 39s 42ms/step - loss: 0.3673 - accuracy: 0.8697 - val_loss: 0.3401 - val_accuracy: 0.8733\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 35s 37ms/step - loss: 0.3379 - accuracy: 0.8789 - val_loss: 0.3210 - val_accuracy: 0.8855\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 34s 37ms/step - loss: 0.3180 - accuracy: 0.8855 - val_loss: 0.2839 - val_accuracy: 0.8949\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 33s 36ms/step - loss: 0.3023 - accuracy: 0.8915 - val_loss: 0.2899 - val_accuracy: 0.8958\n",
      "INFO:tensorflow:Assets written to: ./models/simplest\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/simplest\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 40s 42ms/step - loss: 0.5366 - accuracy: 0.8048 - val_loss: 0.4191 - val_accuracy: 0.8427\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 39s 42ms/step - loss: 0.3953 - accuracy: 0.8606 - val_loss: 0.3347 - val_accuracy: 0.8785\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3548 - accuracy: 0.8745 - val_loss: 0.3091 - val_accuracy: 0.8912\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 39s 42ms/step - loss: 0.3365 - accuracy: 0.8810 - val_loss: 0.3209 - val_accuracy: 0.8809\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3175 - accuracy: 0.8885 - val_loss: 0.4708 - val_accuracy: 0.8361\n",
      "INFO:tensorflow:Assets written to: ./models/deep\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/deep\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 43s 45ms/step - loss: 0.7756 - accuracy: 0.7290 - val_loss: 0.4711 - val_accuracy: 0.8256\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 58s 61ms/step - loss: 0.4819 - accuracy: 0.8338 - val_loss: 0.3952 - val_accuracy: 0.8633\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 46s 49ms/step - loss: 0.4183 - accuracy: 0.8554 - val_loss: 0.3337 - val_accuracy: 0.8816\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 45s 48ms/step - loss: 0.3836 - accuracy: 0.8671 - val_loss: 0.3725 - val_accuracy: 0.8649\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 45s 48ms/step - loss: 0.3620 - accuracy: 0.8751 - val_loss: 0.2948 - val_accuracy: 0.8941\n",
      "INFO:tensorflow:Assets written to: ./models/deepest\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/deepest\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name  accuracy      loss  \\\n",
      "0  simplest    0.8958  0.289879   \n",
      "1      deep    0.8361  0.470821   \n",
      "2   deepest    0.8941  0.294753   \n",
      "\n",
      "                                              layers  \\\n",
      "0                                    643x3reludr0.25   \n",
      "1  323x3relubndr0.2, 643x3relubndr0.2, 1283x3relu...   \n",
      "2  323x3relubndr0.2, 643x3relubndr0.2, 1283x3relu...   \n",
      "\n",
      "                       dense_layers  learning_rate batch_size epochs  \n",
      "0                        128bndr0.5          0.010         64      5  \n",
      "1              64bndr0.2, 32bndr0.2          0.010         64      5  \n",
      "2  128bndr0.2, 64bndr0.2, 32bndr0.2          0.001         64      5  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_7016\\1801560067.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  res = res.append({\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_7016\\1801560067.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  res = res.append({\n",
      "C:\\Users\\askador\\AppData\\Local\\Temp\\ipykernel_7016\\1801560067.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  res = res.append({\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for params in train_params:\n",
    "    if not os.path.isdir(f\"./models/{params['name']}\"):\n",
    "        model = create_model(params)\n",
    "        history = model.fit(x_train, y_train, batch_size=params['batch_size'], epochs=params['epochs'], validation_data=(x_test, y_test), callbacks=[early_stop])\n",
    "        model.save(f\"./models/{params['name']}\")\n",
    "    else:\n",
    "        model = load_model(f\"./models/{params['name']}\")\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        'accuracy': accuracy,\n",
    "        'loss': loss\n",
    "    })\n",
    "\n",
    "for i, r in enumerate(results):\n",
    "    params = r['params']\n",
    "    accuracy, loss = r['accuracy'], r['loss']\n",
    "    layers = ', '.join([f\"{layer['filters']}{layer['kernel_size'][0]}x{layer['kernel_size'][1]}{layer['activation']}{'bn' if layer['batch_norm'] else ''}{'dr' if layer['dropout'] > 0 else ''}{layer['dropout']}\" for layer in params['layers']])\n",
    "    dense_layers = ', '.join([f\"{layer['units']}{'bn' if layer['batch_norm'] else ''}{'dr' if layer['dropout'] > 0 else ''}{layer['dropout']}\" for layer in params['dense_layers']])\n",
    "    res = res.append({\n",
    "        'name': params['name'],\n",
    "        'layers': layers,\n",
    "        'dense_layers': dense_layers,\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'batch_size': params['batch_size'],\n",
    "        'epochs': params['epochs'],\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "    }, ignore_index=True)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>layers</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simplest</td>\n",
       "      <td>0.8958</td>\n",
       "      <td>0.289879</td>\n",
       "      <td>643x3reludr0.25</td>\n",
       "      <td>128bndr0.5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepest</td>\n",
       "      <td>0.8941</td>\n",
       "      <td>0.294753</td>\n",
       "      <td>323x3relubndr0.2, 643x3relubndr0.2, 1283x3relu...</td>\n",
       "      <td>128bndr0.2, 64bndr0.2, 32bndr0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deep</td>\n",
       "      <td>0.8361</td>\n",
       "      <td>0.470821</td>\n",
       "      <td>323x3relubndr0.2, 643x3relubndr0.2, 1283x3relu...</td>\n",
       "      <td>64bndr0.2, 32bndr0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  accuracy      loss  \\\n",
       "0  simplest    0.8958  0.289879   \n",
       "2   deepest    0.8941  0.294753   \n",
       "1      deep    0.8361  0.470821   \n",
       "\n",
       "                                              layers  \\\n",
       "0                                    643x3reludr0.25   \n",
       "2  323x3relubndr0.2, 643x3relubndr0.2, 1283x3relu...   \n",
       "1  323x3relubndr0.2, 643x3relubndr0.2, 1283x3relu...   \n",
       "\n",
       "                       dense_layers  learning_rate batch_size epochs  \n",
       "0                        128bndr0.5          0.010         64      5  \n",
       "2  128bndr0.2, 64bndr0.2, 32bndr0.2          0.001         64      5  \n",
       "1              64bndr0.2, 32bndr0.2          0.010         64      5  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values('accuracy', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a64472e41c1c648b677fc91ca7c70b892e4d44f485f95ef80a40011f0b74dc6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
